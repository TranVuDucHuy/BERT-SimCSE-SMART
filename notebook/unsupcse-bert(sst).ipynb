{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9766909,"sourceType":"datasetVersion","datasetId":5981760},{"sourceId":9795814,"sourceType":"datasetVersion","datasetId":6003130},{"sourceId":10033024,"sourceType":"datasetVersion","datasetId":6179517}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Load SST dataset","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tree import Tree\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom tqdm import tqdm\n\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef read_ptb_tree(tree_string):\n    return Tree.fromstring(tree_string)\n\ndef extract_sentence_and_label(tree):\n    label = (tree.label())\n\n    words = tree.leaves()\n    sentence = ' '.join(words)\n\n    return sentence, label\n\ndef read_file(file_path):\n    data = []\n    with open(file_path, 'r', encoding='utf-8') as file:\n        for line in file:\n            tree = read_ptb_tree(line.strip())\n            sentence, label = extract_sentence_and_label(tree)\n            data.append({'sentence': sentence, 'label': label})\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-11-28T02:21:00.817585Z","iopub.execute_input":"2024-11-28T02:21:00.81824Z","iopub.status.idle":"2024-11-28T02:21:09.740647Z","shell.execute_reply.started":"2024-11-28T02:21:00.818206Z","shell.execute_reply":"2024-11-28T02:21:09.739802Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = '/kaggle/input/treeset/train.txt'\ntest_path = '/kaggle/input/treeset/test.txt'\ndev_path = '/kaggle/input/treeset/dev.txt'\n\ntrain_data = read_file(train_path)\ntest_data = read_file(test_path)\ndev_data = read_file(dev_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-28T02:21:09.741984Z","iopub.execute_input":"2024-11-28T02:21:09.742379Z","iopub.status.idle":"2024-11-28T02:21:10.840766Z","shell.execute_reply.started":"2024-11-28T02:21:09.742352Z","shell.execute_reply":"2024-11-28T02:21:10.839878Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport unicodedata\n\ndef canonicalize_text(text):\n    text = re.sub(r'[\\d\\W_]+', ' ', text)\n\n    text = ''.join(\n        c for c in unicodedata.normalize('NFD', text)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n    text = text.lower()\n\n    text = text.strip()\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-11-28T02:21:10.84189Z","iopub.execute_input":"2024-11-28T02:21:10.842275Z","iopub.status.idle":"2024-11-28T02:21:10.847091Z","shell.execute_reply.started":"2024-11-28T02:21:10.842235Z","shell.execute_reply":"2024-11-28T02:21:10.84631Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SST5_Dataset(Dataset):\n    def __init__(self, file_path):\n        self.data = [\n            (\n                tokenizer(\n                    canonicalize_text(row['sentence']),\n                    add_special_tokens=True,\n                    max_length=512,  \n                    padding='max_length', \n                    truncation=True,      \n                    return_tensors=\"pt\"   \n                ),  \n                int(row['label']) if isinstance(row['label'], str) else row['label']\n            )\n            for row in read_file(file_path)\n        ]\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        X,y = self.data[idx]\n        input_ids = X['input_ids'].squeeze(0)\n        attention_mask = X['attention_mask'].squeeze(0)\n        label = torch.tensor(y, dtype=torch.long)\n        return input_ids, attention_mask, label","metadata":{"execution":{"iopub.status.busy":"2024-11-28T02:21:10.848719Z","iopub.execute_input":"2024-11-28T02:21:10.848958Z","iopub.status.idle":"2024-11-28T02:21:10.859699Z","shell.execute_reply.started":"2024-11-28T02:21:10.848935Z","shell.execute_reply":"2024-11-28T02:21:10.858909Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import BertForSequenceClassification, BertTokenizer\nfrom torch.utils.data import DataLoader, ConcatDataset\n\ntrainset = SST5_Dataset(train_path)\ntestset = SST5_Dataset(test_path)\nvalset = SST5_Dataset(dev_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-28T02:21:10.860518Z","iopub.execute_input":"2024-11-28T02:21:10.860722Z","iopub.status.idle":"2024-11-28T02:21:19.562372Z","shell.execute_reply.started":"2024-11-28T02:21:10.8607Z","shell.execute_reply":"2024-11-28T02:21:19.561588Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from torch.utils.data import Subset\n# import random\n\n# train_indices = random.sample(range(len(trainset)), 500)\n# test_indices = random.sample(range(len(testset)), 100)\n# val_indices = random.sample(range(len(valset)), 100)\n\n# trainset = Subset(trainset, train_indices)\n# testset = Subset(testset, test_indices)\n# valset = Subset(valset, val_indices)","metadata":{"execution":{"iopub.status.busy":"2024-11-28T02:21:19.563314Z","iopub.execute_input":"2024-11-28T02:21:19.563751Z","iopub.status.idle":"2024-11-28T02:21:19.56918Z","shell.execute_reply.started":"2024-11-28T02:21:19.563724Z","shell.execute_reply":"2024-11-28T02:21:19.568214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_unsupervised_sentences(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        sentences = file.readlines()\n    return [sentence.strip() for sentence in sentences]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T02:21:19.570271Z","iopub.execute_input":"2024-11-28T02:21:19.570546Z","iopub.status.idle":"2024-11-28T02:21:19.579611Z","shell.execute_reply.started":"2024-11-28T02:21:19.570521Z","shell.execute_reply":"2024-11-28T02:21:19.578767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wiki_path = '/kaggle/input/sampled-wiki/processed_sentences.txt'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T02:21:19.580487Z","iopub.execute_input":"2024-11-28T02:21:19.580742Z","iopub.status.idle":"2024-11-28T02:21:19.591168Z","shell.execute_reply.started":"2024-11-28T02:21:19.580718Z","shell.execute_reply":"2024-11-28T02:21:19.590395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class WikiDataset(Dataset):\n    def __init__(self, file_path, tokenizer, max_length=512):\n        self.data = []\n        with open(file_path, 'r', encoding='utf-8') as f:\n            for line in f:\n                sentence = line.strip()\n                tokenized = tokenizer(\n                    sentence,\n                    add_special_tokens=True,\n                    max_length=max_length,\n                    padding=\"max_length\",\n                    truncation=True,\n                    return_tensors=\"pt\"\n                )\n                self.data.append(tokenized)\n\n        # self.data = self.data[:100]   ##sampling\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        tokenized = self.data[idx]\n        input_ids = tokenized['input_ids'].squeeze(0) \n        attention_mask = tokenized['attention_mask'].squeeze(0)\n        dummy_label = torch.tensor(-1, dtype=torch.long)\n        return input_ids, attention_mask, dummy_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T02:21:19.592168Z","iopub.execute_input":"2024-11-28T02:21:19.592497Z","iopub.status.idle":"2024-11-28T02:21:19.600436Z","shell.execute_reply.started":"2024-11-28T02:21:19.59246Z","shell.execute_reply":"2024-11-28T02:21:19.5996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wiki_dataset = WikiDataset(wiki_path, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T02:21:19.60355Z","iopub.execute_input":"2024-11-28T02:21:19.603793Z","iopub.status.idle":"2024-11-28T02:21:47.625307Z","shell.execute_reply.started":"2024-11-28T02:21:19.603769Z","shell.execute_reply":"2024-11-28T02:21:47.624592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unsup_trainset = ConcatDataset([wiki_dataset, trainset])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T02:21:47.626393Z","iopub.execute_input":"2024-11-28T02:21:47.626678Z","iopub.status.idle":"2024-11-28T02:21:47.630992Z","shell.execute_reply.started":"2024-11-28T02:21:47.62665Z","shell.execute_reply":"2024-11-28T02:21:47.630082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BertModel\n\nimport logging\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import classification_report, f1_score, recall_score, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-11-28T02:21:47.631938Z","iopub.execute_input":"2024-11-28T02:21:47.632191Z","iopub.status.idle":"2024-11-28T02:21:47.650883Z","shell.execute_reply.started":"2024-11-28T02:21:47.632167Z","shell.execute_reply":"2024-11-28T02:21:47.650248Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class UnSup_BERT(nn.Module):\n    def __init__(self, bert, is_unsup_train=True):\n        super(UnSup_BERT, self).__init__()\n\n        self.bert = bert\n        self.dropout = nn.Dropout(0.3)\n        self.is_unsup_train = is_unsup_train\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=False)\n        pooled = outputs['pooler_output']\n\n        if not self.is_unsup_train:\n            return pooled\n\n        return self.dropout(pooled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T02:21:47.651936Z","iopub.execute_input":"2024-11-28T02:21:47.652185Z","iopub.status.idle":"2024-11-28T02:21:47.662618Z","shell.execute_reply.started":"2024-11-28T02:21:47.65216Z","shell.execute_reply":"2024-11-28T02:21:47.661873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bert = BertModel.from_pretrained('bert-base-uncased')\nuncl_model = UnSup_BERT(bert, is_unsup_train=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuncl_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T02:21:47.663535Z","iopub.execute_input":"2024-11-28T02:21:47.663851Z","iopub.status.idle":"2024-11-28T02:21:50.591205Z","shell.execute_reply.started":"2024-11-28T02:21:47.663817Z","shell.execute_reply":"2024-11-28T02:21:50.590245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Train with Unsupervised SimCSE\ndef train_uncl(model, criterion, trainset, batch_size, epochs, path='/kaggle/working/best_model_uncl.pth'):\n     train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n\n     optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n\n     for epoch in range(epochs):\n         model.train()\n\n         train_loss = 0.0\n         for batch in tqdm(train_loader, desc=f\"Training SimCSE ...:\"):\n             b_ids, b_mask, *_ = batch\n\n             b_ids = b_ids.to(device)\n             b_mask = b_mask.to(device)\n\n             optimizer.zero_grad()\n\n             emb1 = model(b_ids, b_mask)\n             emb2 = model(b_ids, b_mask)\n\n             sim_matrix = F.cosine_similarity(emb1.unsqueeze(1), emb2.unsqueeze(0), dim=-1)\n             sim_matrix = sim_matrix / 0.05\n             labels_CL = torch.arange(b_ids.size(0)).long()\n             labels_CL = labels_CL.to(sim_matrix.device) \n             \n             loss = F.cross_entropy(sim_matrix, labels_CL)\n                          \n             loss.backward()\n             optimizer.step()\n\n             train_loss += loss.item()\n\n         train_loss /= len(train_loader)\n\n         print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}\")\n        \n     torch.save(model.state_dict(), path)   \n        \n     return model\n\ntrain_uncl(uncl_model, nn.CrossEntropyLoss(), unsup_trainset, batch_size=4, epochs=3)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-28T02:21:50.592125Z","iopub.execute_input":"2024-11-28T02:21:50.592369Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"uncl_model = UnSup_BERT(bert, is_unsup_train=False)\nuncl_model.load_state_dict(torch.load('/kaggle/working/best_model_uncl.pth'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define BERT CLassifier","metadata":{}},{"cell_type":"code","source":"class BertClassifier(nn.Module):\n    def __init__(self, num_labels):\n        super(BertClassifier, self).__init__()\n        self.bert = uncl_model\n        # Frozen bert\n        #self.bert.requires_grad_(False)\n\n        #self.dropout = nn.Dropout(0.1)\n        self.classifier = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_labels)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        #pooled_output = outputs.pooler_output\n        #pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(outputs)\n        return logits","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define train and eval classification","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    train_loss = 0.0\n\n    for input_ids, attention_mask, labels in tqdm(dataloader, desc=\"Training\"):\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        logits = model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    train_loss /= len(dataloader)\n\n    print(f\"Train Loss: {train_loss:.4f}\")\n    return train_loss\n\ndef eval_one_epoch(model, dataloader, criterion, device):\n    model.eval()\n    eval_loss = 0.0\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for input_ids, attention_mask, labels in tqdm(dataloader, desc=\"Evaluating\"):\n          \n            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n\n            eval_loss += loss.item()\n\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n\n    eval_loss /= len(dataloader)\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Eval Loss: {eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n\n    return eval_loss, accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_cls(model, criterion, trainset, valset, epochs, save_dir='/kaggle/working/'):\n    train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(valset, batch_size=32, shuffle=False)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n    \n    best_model_path = f\"{save_dir}best_model_cls.pth\"\n\n    best_val_loss = float('inf')\n    for epoch in range(epochs):\n        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, accuracy= eval_one_epoch(model, val_loader, criterion, device)\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"Save model at epoch {epoch + 1}\")\n\n    return model\n\nmodel = BertClassifier(5)\nmodel.to(device)\n\ncls_model = train_cls(model, nn.CrossEntropyLoss(), trainset, valset, 6)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test and visual result","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport numpy as np\n\ndef test_model(model_path, testset, device, batch_size=32):\n\n    model = BertClassifier(num_labels=5)\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    model.to(device)\n    \n    test_loader = DataLoader(testset, batch_size=batch_size)\n    \n    all_preds = []\n    all_labels = []\n    total_loss = 0\n    correct_predictions = 0\n    \n    with torch.no_grad():\n        for input_ids, attention_mask, labels in tqdm(test_loader, desc=\"Testing\"):\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(input_ids, attention_mask=attention_mask)\n            loss = F.cross_entropy(outputs, labels)\n            total_loss += loss.item()\n            \n            # Get predictions\n            preds = torch.argmax(outputs, dim=1)\n            correct_predictions += torch.sum(preds == labels).item()\n            \n            # Store predictions and labels for metric calculation\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Calculate metrics\n    accuracy = correct_predictions / len(testset)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        all_labels, \n        all_preds, \n        average='weighted'\n    )\n    avg_loss = total_loss / len(test_loader)\n    \n    # Print metrics\n    print(f\"Test Loss: {avg_loss:.4f}\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    \n    # Calculate and plot confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(\n        cm, \n        annot=True, \n        fmt='d', \n        cmap='Blues',\n        xticklabels=np.unique(all_labels),\n        yticklabels=np.unique(all_labels)\n    )\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.tight_layout()\n    plt.show()\n    \n    metrics = {\n        'loss': avg_loss,\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'confusion_matrix': cm\n    }\n    \n    return metrics\n\nmodel_path = '/kaggle/working/best_model_cls.pth'\n\nmetrics = test_model(\n    model_path=model_path,\n    testset=testset,\n    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}