{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9766909,"sourceType":"datasetVersion","datasetId":5981760},{"sourceId":9795814,"sourceType":"datasetVersion","datasetId":6003130},{"sourceId":9908213,"sourceType":"datasetVersion","datasetId":6085014}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk\nfrom nltk.tree import Tree\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom tqdm import tqdm\n\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef read_ptb_tree(tree_string):\n    return Tree.fromstring(tree_string)\n\ndef extract_sentence_and_label(tree):\n    label = (tree.label())\n\n    words = tree.leaves()\n    sentence = ' '.join(words)\n\n    return sentence, label\n\ndef read_file(file_path):\n    data = []\n    with open(file_path, 'r', encoding='utf-8') as file:\n        for line in file:\n            tree = read_ptb_tree(line.strip())\n            sentence, label = extract_sentence_and_label(tree)\n            data.append({'sentence': sentence, 'label': label})\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:25.665643Z","iopub.execute_input":"2024-11-17T05:01:25.66619Z","iopub.status.idle":"2024-11-17T05:01:35.77532Z","shell.execute_reply.started":"2024-11-17T05:01:25.666139Z","shell.execute_reply":"2024-11-17T05:01:35.774344Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = '/kaggle/input/treeset/train.txt'\ntest_path = '/kaggle/input/treeset/test.txt'\ndev_path = '/kaggle/input/treeset/dev.txt'\n\ntrain_data = read_file(train_path)\ntest_data = read_file(test_path)\ndev_data = read_file(dev_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:35.776678Z","iopub.execute_input":"2024-11-17T05:01:35.777319Z","iopub.status.idle":"2024-11-17T05:01:38.264765Z","shell.execute_reply.started":"2024-11-17T05:01:35.777268Z","shell.execute_reply":"2024-11-17T05:01:38.26397Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def group_data_by_level(data):\n    data_by_level = {}\n    \n    for item in data:\n        label = int(item['label']) \n        sentence = item['sentence']\n        \n        if label not in data_by_level:\n            data_by_level[label] = []\n        \n        data_by_level[label].append(sentence)\n    \n    return data_by_level\n\ndata_by_level = group_data_by_level(train_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:38.265895Z","iopub.execute_input":"2024-11-17T05:01:38.266233Z","iopub.status.idle":"2024-11-17T05:01:38.276799Z","shell.execute_reply.started":"2024-11-17T05:01:38.266201Z","shell.execute_reply":"2024-11-17T05:01:38.275869Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\ndef create_large_data_pairs(data_by_level, target_size):\n    pairs = []\n    levels = list(data_by_level.keys())  \n    \n    while len(pairs) < target_size:\n        for level in levels:\n            level_data = data_by_level[level]\n            if len(level_data) < 2:\n                continue  \n            \n            sen0, sent1 = random.sample(level_data, 2)\n            \n            if level == 0:\n                hard_neg_level = 1\n            elif level == 4:\n                hard_neg_level = 3\n            else:\n                hard_neg_level = random.choice([level - 1, level + 1])\n            \n            hard_neg = random.choice(data_by_level[hard_neg_level])\n            \n            pairs.append((sen0, sent1, hard_neg))\n            \n            if len(pairs) >= target_size:\n                break\n    \n    return pairs\n\ntarget_size = 300000\n\npairs = create_large_data_pairs(data_by_level, target_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:38.279484Z","iopub.execute_input":"2024-11-17T05:01:38.279797Z","iopub.status.idle":"2024-11-17T05:01:40.350989Z","shell.execute_reply.started":"2024-11-17T05:01:38.279765Z","shell.execute_reply":"2024-11-17T05:01:40.350052Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pairs = list(set(pairs))","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:40.352199Z","iopub.execute_input":"2024-11-17T05:01:40.352583Z","iopub.status.idle":"2024-11-17T05:01:40.409978Z","shell.execute_reply.started":"2024-11-17T05:01:40.352534Z","shell.execute_reply":"2024-11-17T05:01:40.408919Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pairs = pairs[:1000] ##sampling","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:40.41137Z","iopub.execute_input":"2024-11-17T05:01:40.411796Z","iopub.status.idle":"2024-11-17T05:01:40.419237Z","shell.execute_reply.started":"2024-11-17T05:01:40.41173Z","shell.execute_reply":"2024-11-17T05:01:40.418306Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport unicodedata\n\ndef canonicalize_text(text):\n    text = re.sub(r'[\\d\\W_]+', ' ', text)\n\n    text = ''.join(\n        c for c in unicodedata.normalize('NFD', text)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n    text = text.lower()\n\n    text = text.strip()\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:40.420389Z","iopub.execute_input":"2024-11-17T05:01:40.420695Z","iopub.status.idle":"2024-11-17T05:01:40.428648Z","shell.execute_reply.started":"2024-11-17T05:01:40.420664Z","shell.execute_reply":"2024-11-17T05:01:40.427748Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SST5_Dataset(Dataset):\n    def __init__(self, file_path):\n        self.data = [\n            (\n                tokenizer(\n                    canonicalize_text(row['sentence']),\n                    add_special_tokens=True,\n                    max_length=512,  \n                    padding='max_length', \n                    truncation=True,      \n                    return_tensors=\"pt\"   \n                ),  \n                int(row['label']) if isinstance(row['label'], str) else row['label']\n            )\n            for row in read_file(file_path)\n        ]\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        X,y = self.data[idx]\n        input_ids = X['input_ids'].squeeze(0)\n        attention_mask = X['attention_mask'].squeeze(0)\n        label = torch.tensor(y, dtype=torch.long)\n        return input_ids, attention_mask, label","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:40.429793Z","iopub.execute_input":"2024-11-17T05:01:40.430199Z","iopub.status.idle":"2024-11-17T05:01:40.438414Z","shell.execute_reply.started":"2024-11-17T05:01:40.430166Z","shell.execute_reply":"2024-11-17T05:01:40.437543Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import BertForSequenceClassification, BertTokenizer\nfrom torch.utils.data import DataLoader\n\ntrainset = SST5_Dataset(train_path)\ntestset = SST5_Dataset(test_path)\nvalset = SST5_Dataset(dev_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:40.439653Z","iopub.execute_input":"2024-11-17T05:01:40.439993Z","iopub.status.idle":"2024-11-17T05:01:47.407987Z","shell.execute_reply.started":"2024-11-17T05:01:40.439953Z","shell.execute_reply":"2024-11-17T05:01:47.406253Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from torch.utils.data import Subset\n# import random\n\n# train_indices = random.sample(range(len(trainset)), 500)\n# test_indices = random.sample(range(len(testset)), 100)\n# val_indices = random.sample(range(len(valset)), 100)\n\n# trainset = Subset(trainset, train_indices)\n# testset = Subset(testset, test_indices)\n# valset = Subset(valset, val_indices)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:47.40893Z","iopub.status.idle":"2024-11-17T05:01:47.409302Z","shell.execute_reply.started":"2024-11-17T05:01:47.409119Z","shell.execute_reply":"2024-11-17T05:01:47.409138Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BertTokenizer\n\ndef create_triples(pairs):\n    triples = []\n\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    \n    for sen0, sent1, hard_neg in tqdm(pairs):\n\n        anchor = canonicalize_text(sen0)\n        pos = canonicalize_text(sent1)\n        neg = canonicalize_text(hard_neg)\n\n        anchor_tokens = tokenizer.tokenize('[CLS] ' + anchor + ' [SEP]')\n        pos_tokens = tokenizer.tokenize('[CLS] ' + pos + ' [SEP]')\n        neg_tokens = tokenizer.tokenize('[CLS] ' + neg + ' [SEP]')\n        \n        triples.append((anchor, anchor_tokens, pos, pos_tokens, neg, neg_tokens))\n\n    return triples\n\nnli_data = create_triples(pairs)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:47.410489Z","iopub.status.idle":"2024-11-17T05:01:47.410828Z","shell.execute_reply.started":"2024-11-17T05:01:47.410658Z","shell.execute_reply":"2024-11-17T05:01:47.410675Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom transformers import BertTokenizer\nimport numpy as np\n\nclass NLI_Dataset(Dataset):\n    def __init__(self, triples):\n        self.triples = triples\n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n    def __len__(self):\n        return len(self.triples)\n\n    def __getitem__(self, idx):\n        return self.triples[idx]\n\n    def pad_data(self, data):\n        anchor = [x[0] for x in data]\n        pos = [x[2] for x in data]\n        neg = [x[4] for x in data]\n\n        encoding_anchor = self.tokenizer(anchor, return_tensors='pt', padding=True, truncation=True)\n        token_ids_anchor = encoding_anchor['input_ids']\n        attention_mask_anchor = encoding_anchor['attention_mask']\n\n        encoding_pos = self.tokenizer(pos, return_tensors='pt', padding=True, truncation=True)\n        token_ids_pos = encoding_pos['input_ids']\n        attention_mask_pos = encoding_pos['attention_mask']\n\n        encoding_neg = self.tokenizer(neg, return_tensors='pt', padding=True, truncation=True)\n        token_ids_neg = encoding_neg['input_ids']\n        attention_mask_neg = encoding_neg['attention_mask']\n\n        return token_ids_anchor, attention_mask_anchor, token_ids_pos, attention_mask_pos, token_ids_neg, attention_mask_neg\n\n    def collate_fn(self, all_data):\n        all_data.sort(key=lambda x: -len(x[1]))\n\n        batches = []\n        num_batches = int(np.ceil(len(all_data) / 32)) \n\n        for i in range(num_batches):\n            start_idx = i * 32\n            data = all_data[start_idx: start_idx + 32]\n\n            token_ids_anchor, attention_mask_anchor, \\\n            token_ids_pos, attention_mask_pos, \\\n            token_ids_neg, attention_mask_neg = self.pad_data(data)\n\n            batches.append({\n                'token_ids_anchor': token_ids_anchor,\n                'attention_mask_anchor': attention_mask_anchor,\n                'token_ids_pos': token_ids_pos,\n                'attention_mask_pos': attention_mask_pos,\n                'token_ids_neg': token_ids_neg,\n                'attention_mask_neg': attention_mask_neg,\n            })\n\n        return batches\n\nNLI_dataset = NLI_Dataset(nli_data)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:47.411877Z","iopub.status.idle":"2024-11-17T05:01:47.412246Z","shell.execute_reply.started":"2024-11-17T05:01:47.412071Z","shell.execute_reply":"2024-11-17T05:01:47.412091Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BertModel\n\nimport logging\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import classification_report, f1_score, recall_score, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:47.413785Z","iopub.status.idle":"2024-11-17T05:01:47.414336Z","shell.execute_reply.started":"2024-11-17T05:01:47.414055Z","shell.execute_reply":"2024-11-17T05:01:47.414084Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def supCL_loss(criterion, anchor, pos, neg, new_w=0, temper=0.05):\n    cos = nn.CosineSimilarity(dim=-1)\n    pos_sim = cos(anchor.unsqueeze(1), pos.unsqueeze(0)) / temper\n    neg_sim = cos(anchor.unsqueeze(1), neg.unsqueeze(0)) / temper\n\n    cos_sim = torch.cat([pos_sim, neg_sim], dim=1)\n    labels = torch.arange(cos_sim.size(0)).long().to(anchor.device)\n    weights = torch.tensor(\n        [[0.0] * (cos_sim.size(-1) - neg_sim.size(-1)) + [0.0] * i + [new_w] + [0.0] * (neg_sim.size(-1) - i - 1) for i in range(neg_sim.size(-1))]\n    ).to(anchor.device)\n    cos_sim += weights\n    loss = criterion(cos_sim, labels)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:47.416428Z","iopub.status.idle":"2024-11-17T05:01:47.416786Z","shell.execute_reply.started":"2024-11-17T05:01:47.416603Z","shell.execute_reply":"2024-11-17T05:01:47.416628Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = BertModel.from_pretrained('bert-base-uncased')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Train with SimCSE\ndef train_cl(model, criterion, cl_loss, trainset, epochs, path='/kaggle/working/best_model_cl.pth'):\n    train_loader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=NLI_dataset.collate_fn)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n\n    for epoch in range(epochs):\n        model.train()\n\n        train_loss = 0.0\n        for batch in tqdm(train_loader, desc=f\"Training SimCSE ...:\"):\n            optimizer.zero_grad()\n            input_ids_anchor = batch[0]['token_ids_anchor'].to(device)\n            attention_mask_anchor = batch[0]['attention_mask_anchor'].to(device)\n            input_ids_pos = batch[0]['token_ids_pos'].to(device)\n            attention_mask_pos = batch[0]['attention_mask_pos'].to(device)\n            input_ids_neg = batch[0]['token_ids_neg'].to(device)\n            attention_mask_neg = batch[0]['attention_mask_neg'].to(device)\n\n            anchor_output = model(input_ids_anchor, attention_mask_anchor)['pooler_output']\n            pos_output = model(input_ids_pos, attention_mask_pos)['pooler_output']\n            neg_output = model(input_ids_neg, attention_mask_neg)['pooler_output']\n\n            loss = cl_loss(criterion, anchor_output, pos_output, neg_output)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        train_loss /= len(train_loader)\n\n        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}\")\n        \n    torch.save(model.state_dict(), path)   \n        \n    return model\n\ncl_model = train_cl(model, nn.CrossEntropyLoss(), supCL_loss, NLI_dataset, epochs=3)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:47.418003Z","iopub.status.idle":"2024-11-17T05:01:47.418657Z","shell.execute_reply.started":"2024-11-17T05:01:47.418177Z","shell.execute_reply":"2024-11-17T05:01:47.418196Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BertClassifier(nn.Module):\n    def __init__(self, num_labels):\n        super(BertClassifier, self).__init__()\n        self.bert = cl_model\n        # Frozen bert\n        #self.bert.requires_grad_(False)\n\n        self.dropout = nn.Dropout(0.1)\n        self.classifier = nn.Sequential(\n            nn.Linear(768, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_labels)\n        )\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:47.420302Z","iopub.status.idle":"2024-11-17T05:01:47.420667Z","shell.execute_reply.started":"2024-11-17T05:01:47.420487Z","shell.execute_reply":"2024-11-17T05:01:47.420507Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    train_loss = 0.0\n\n    for input_ids, attention_mask, labels in tqdm(dataloader, desc=\"Training\"):\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        logits = model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    train_loss /= len(dataloader)\n\n    print(f\"Train Loss: {train_loss:.4f}\")\n    return train_loss\n\ndef eval_one_epoch(model, dataloader, criterion, device):\n    model.eval()\n    eval_loss = 0.0\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for input_ids, attention_mask, labels in tqdm(dataloader, desc=\"Evaluating\"):\n          \n            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n\n            eval_loss += loss.item()\n\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n\n    eval_loss /= len(dataloader)\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Eval Loss: {eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n\n    return eval_loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:47.421599Z","iopub.status.idle":"2024-11-17T05:01:47.42197Z","shell.execute_reply.started":"2024-11-17T05:01:47.421767Z","shell.execute_reply":"2024-11-17T05:01:47.421786Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_cls(model, criterion, trainset, valset, epochs, save_dir='/kaggle/working/'):\n    train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(valset, batch_size=32, shuffle=False)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n    \n    best_model_path = f\"{save_dir}best_model_cls.pth\"\n\n    best_val_loss = float('inf')\n    for epoch in range(epochs):\n        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, accuracy= eval_one_epoch(model, val_loader, criterion, device)\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"Save model at epoch {epoch + 1}\")\n\n    return model\n\nmodel = BertClassifier(5)\nmodel.to(device)\n\ncls_model = train_cls(model, nn.CrossEntropyLoss(), trainset, valset, 6)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:47.423561Z","iopub.status.idle":"2024-11-17T05:01:47.423961Z","shell.execute_reply.started":"2024-11-17T05:01:47.423744Z","shell.execute_reply":"2024-11-17T05:01:47.423764Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport numpy as np\n\ndef test_model(model_path, testset, device, batch_size=32):\n\n    model = BertClassifier(num_labels=5)\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    model.to(device)\n    \n    test_loader = DataLoader(testset, batch_size=batch_size)\n    \n    all_preds = []\n    all_labels = []\n    total_loss = 0\n    correct_predictions = 0\n    \n    with torch.no_grad():\n        for input_ids, attention_mask, labels in tqdm(test_loader, desc=\"Testing\"):\n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(input_ids, attention_mask=attention_mask)\n            loss = F.cross_entropy(outputs, labels)\n            total_loss += loss.item()\n            \n            # Get predictions\n            preds = torch.argmax(outputs, dim=1)\n            correct_predictions += torch.sum(preds == labels).item()\n            \n            # Store predictions and labels for metric calculation\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Calculate metrics\n    accuracy = correct_predictions / len(testset)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        all_labels, \n        all_preds, \n        average='weighted'\n    )\n    avg_loss = total_loss / len(test_loader)\n    \n    # Print metrics\n    print(f\"Test Loss: {avg_loss:.4f}\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    \n    # Calculate and plot confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(\n        cm, \n        annot=True, \n        fmt='d', \n        cmap='Blues',\n        xticklabels=np.unique(all_labels),\n        yticklabels=np.unique(all_labels)\n    )\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.tight_layout()\n    plt.show()\n    \n    metrics = {\n        'loss': avg_loss,\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'confusion_matrix': cm\n    }\n    \n    return metrics\n\nmodel_path = '/kaggle/working/best_model.pth'\n\nmetrics = test_model(\n    model_path=model_path,\n    testset=testset,\n    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T05:01:47.425014Z","iopub.status.idle":"2024-11-17T05:01:47.425342Z","shell.execute_reply.started":"2024-11-17T05:01:47.425174Z","shell.execute_reply":"2024-11-17T05:01:47.425191Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}